\section*{Abstract}

\selectlanguage{english}

The increasing use of artificial neural networks (ANNs) in security areas makes it imperative to understand the way in which adversarial attacks on these networks act. Thus, we tried here to throw some light in this direction by experimenting and analyzing the effects that attacks, defenses, overfitting and overparameterization have on the networks, and also by saliency and transfer function analysis. We found that, although an initial hypothesis was that the networks are susceptible to adversarial attacks due to their lack of filter (in a control theory sense), there is actually several responses of the networks that make us think the opposite. This shows that there is still a lot to understand and develop in order to have a more robust behavior for the ANNs. \\[1cm]

\noindent\textbf{Keywords}: neural networks, adversarial attacks, JPEG defense, saliency, overfitting, overparameterization, transfer function, 2D FFT